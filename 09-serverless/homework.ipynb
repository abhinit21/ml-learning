{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\surak\\Git Clones\\ml-learning\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.lite as tflite"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:08.523044Z",
     "start_time": "2023-11-27T13:22:47.878677900Z"
    }
   },
   "id": "3929ded84d703d62"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "23860055f635bf45"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:10.245815400Z",
     "start_time": "2023-11-27T13:23:08.525070300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\surak\\Git Clones\\ml-learning\\venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "WARNING:tensorflow:From C:\\Users\\surak\\Git Clones\\ml-learning\\venv\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./bees-wasps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:10.367248400Z",
     "start_time": "2023-11-27T13:23:10.246811400Z"
    }
   },
   "id": "815b3f9e400cf0c8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\surak\\AppData\\Local\\Temp\\tmpj_gvnvz_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\surak\\AppData\\Local\\Temp\\tmpj_gvnvz_\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:16.585566600Z",
     "start_time": "2023-11-27T13:23:10.288010400Z"
    }
   },
   "id": "c646567538372adb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with open('./bees-wasps.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:16.696271300Z",
     "start_time": "2023-11-27T13:23:16.592074700Z"
    }
   },
   "id": "50060c789fea1ae"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file size: 44.8662 MB\n"
     ]
    }
   ],
   "source": [
    "file_size_bytes = os.stat('bees-wasps.tflite').st_size\n",
    "file_size_mb = file_size_bytes / 1000000\n",
    "print(\"Model file size:\", file_size_mb, \"MB\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:16.760092500Z",
     "start_time": "2023-11-27T13:23:16.700282500Z"
    }
   },
   "id": "f3bf6f110e256989"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter('./bees-wasps.tflite')\n",
    "interpreter.allocate_tensors()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:16.893592Z",
     "start_time": "2023-11-27T13:23:16.737995500Z"
    }
   },
   "id": "a8fb319356421034"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()[0]['index']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:16.895605600Z",
     "start_time": "2023-11-27T13:23:16.872771700Z"
    }
   },
   "id": "c1dbcaaebad61c87"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:16.925235400Z",
     "start_time": "2023-11-27T13:23:16.898616Z"
    }
   },
   "id": "1a9c18f1a5db20a5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "test_url = 'https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg'\n",
    "test_image = download_image(test_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:18.066944200Z",
     "start_time": "2023-11-27T13:23:16.909649300Z"
    }
   },
   "id": "c0f391ecfb2290a1"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "target_size = (150, 150)\n",
    "processed_image = prepare_image(test_image, target_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:18.147155200Z",
     "start_time": "2023-11-27T13:23:18.067945600Z"
    }
   },
   "id": "1b2eeaaf6479c854"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "image_array = np.array(processed_image)\n",
    "image_array = image_array.reshape((1,) + image_array.shape)\n",
    "image_array = image_array / 255"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:22.959803600Z",
     "start_time": "2023-11-27T13:23:22.925481800Z"
    }
   },
   "id": "2e8649879aeadca8"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9450980392156862"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_value = image_array[0, 0, 0, 0]\n",
    "r_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:23:51.099474200Z",
     "start_time": "2023-11-27T13:23:51.090259200Z"
    }
   },
   "id": "f1adf5fd1ece3d67"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_conv2d_input:0 ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m input_data \u001B[38;5;241m=\u001B[39m image_array\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Set the input tensor with input data\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m \u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_details\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mindex\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Invoke the interpreter to perform inference\u001B[39;00m\n\u001B[0;32m     17\u001B[0m interpreter\u001B[38;5;241m.\u001B[39minvoke()\n",
      "File \u001B[1;32m~\\Git Clones\\ml-learning\\venv\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:720\u001B[0m, in \u001B[0;36mInterpreter.set_tensor\u001B[1;34m(self, tensor_index, value)\u001B[0m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_tensor\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor_index, value):\n\u001B[0;32m    705\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001B[39;00m\n\u001B[0;32m    706\u001B[0m \n\u001B[0;32m    707\u001B[0m \u001B[38;5;124;03m  Note this copies data in `value`.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    718\u001B[0m \u001B[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001B[39;00m\n\u001B[0;32m    719\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 720\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSetTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_conv2d_input:0 "
     ]
    }
   ],
   "source": [
    "# Load TFLite model:\n",
    "model_path = './bees-wasps.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# define input data (x is image prepared above)\n",
    "input_data = image_array\n",
    "\n",
    "# Set the input tensor with input data\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Invoke the interpreter to perform inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# The output_data now contains the model's prediction\n",
    "print(\"Model Prediction:\", output_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:24:41.437904Z",
     "start_time": "2023-11-27T13:24:41.256664100Z"
    }
   },
   "id": "a1fd96b223e12fdc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
